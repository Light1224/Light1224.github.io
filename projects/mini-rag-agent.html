<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8">
		<title>Mini RAG Agent</title>
		<link rel="stylesheet" href="../style.css">

		<style>
			.section {
				margin-bottom: 48px;
			}
			
			.subsection {
				margin-top: 24px;
				margin-bottom: 24px;
			}
			
			.image-container {
				width: 100%;
				display: flex;
				justify-content: center;
				margin: 24px 0;
			}
			
			.image-container img {
				max-width: 100%;
				height: auto;
				object-fit: contain;
				border-radius: 6px;
			}
			
			ul ul {
				margin-top: 8px;
				margin-bottom: 8px;
			}
		</style>
	</head>

	<body>
		<div class="layout">
			<nav class="sidebar">
				<div class="name">SHAMIT</div>
				<div class="line"></div>
				<a href="../index.html">About</a>
				<a href="../projects.html" class="active">Projects</a>
				<a href="../putnam.html">Putnam</a>
				<a href="../imc.html">IMC</a>
				<a href="../cv.pdf" target="_blank">CV</a>
			</nav>

			<main class="content">
				<h2>Mini RAG Agent</h2>

				<!-- WHAT THIS PROJECT IS -->
				<div class="section">
					<h3>What This Project Is</h3>
					<ul>
						<li>Full Retrieval-Augmented Generation (RAG) system</li>
						<li>Allows uploading text documents and asking questions</li>
						<li>Answers are generated strictly using uploaded documents</li>
						<li>System composed of multiple interacting layers</li>
					</ul>

					<div class="subsection">
						<h3>System Characteristics</h3>
						<ul>
							<li>Explicit ingestion layer</li>
							<li>Persistent storage layer</li>
							<li>Embedding pipeline</li>
							<li>Vector-based retrieval</li>
							<li>Constrained generation layer</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Primary Goal</h3>
						<ul>
							<li>Understand modern AI systems end to end</li>
							<li>Study interaction between LLMs, vector search, and databases</li>
							<li>Expose real-world edge cases tutorials usually hide</li>
						</ul>
					</div>
				</div>

				<!-- SYSTEM OVERVIEW -->
				<div class="section">
					<h2>System Overview</h2>
					<ul>
						<li>Pipeline-based design with strict boundaries</li>
						<li>Each stage is explicit, isolated, and debuggable</li>
					</ul>

					<div class="subsection">
						<h3>Pipeline Stages</h3>
						<ul>
							<li>Documents enter the system (ingestion)</li>
							<li>Documents are broken into chunks (processing)</li>
							<li>Chunks are converted into vectors (embedding)</li>
							<li>Questions are converted into vectors (query embedding)</li>
							<li>Similar chunks are retrieved (retrieval)</li>
							<li>LLM answers using only retrieved chunks (generation)</li>
						</ul>
					</div>

					<div class="subsection">
						<ul>
							<li>If something breaks, the exact layer is identifiable</li>
						</ul>
					</div>

					<div class="image-container">
						<img src="minirag.png" alt="Mini RAG System Overview Mermaid Diagram">
					</div>
				</div>

				<!-- TECH STACK -->
				<div class="section">
					<h2>Tech Stack</h2>

					<div class="subsection">
						<h3>Backend</h3>
						<ul>
							<li><strong>Language:</strong>
							Python 3.11
							<ul>
								<li>Strong AI ecosystem</li>
								<li>Mature async support</li>
								<li>Fast iteration prioritized over raw performance</li>
							</ul></li>

							<li><strong>Web Framework:</strong>
							FastAPI
							<ul>
								<li>Strict request/response validation</li>
								<li>Automatic OpenAPI documentation</li>
								<li>Async-first design</li>
								<li>Clean dependency injection</li>
							</ul></li>

							<li><strong>Server:</strong>
							Uvicorn
							<ul>
								<li>ASGI server</li>
								<li>Simple setup with good async performance</li>
							</ul></li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Persistence</h3>
						<ul>
							<li><strong>Database:</strong>
							PostgreSQL
							<ul>
								<li>Production-like behavior</li>
								<li>Real constraint and transaction handling</li>
							</ul></li>

							<li><strong>ORM:</strong>
							SQLAlchemy
							<ul>
								<li>Full schema and constraint control</li>
								<li>Safe schema evolution</li>
								<li>Ability to drop to raw SQL</li>
							</ul></li>
						</ul>
					</div>

					<div class="subsection">
						<h3>ML Stack</h3>
						<ul>
							<li><strong>Embeddings:</strong>
							Ollama + nomic-embed-text
							<ul>
								<li>Local inference</li>
								<li>No cloud APIs</li>
								<li>Stable, high-quality embeddings</li>
							</ul></li>

							<li><strong>LLM:</strong>
							Ollama (gemma2:2)
							<ul>
								<li>Fully local generation</li>
								<li>No rate limits or API keys</li>
								<li>Model swapping via configuration</li>
							</ul></li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Frontend</h3>
						<ul>
							<li><strong>Frontend:</strong>
							HTML, CSS, Vanilla JavaScript
							<ul>
								<li>No React or frameworks</li>
								<li>State bugs remain visible</li>
							</ul></li>
						</ul>
					</div>
				</div>

				<!-- PHASES -->
				<div class="section">
					<h2>System Phases</h2>

					<div class="subsection">
						<h3>Phase 1: Document Ingestion</h3>
						<ul>
							<li>TXT files only</li>
							<li>Raw file bytes read</li>
							<li>Explicit UTF-8 decoding</li>
							<li>SHA-256 hash computed from content</li>
							<li>Deduplication via content hash</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 2: Database Design</h3>
						<ul>
							<li>documents table</li>
							<li>chunks table</li>
							<li>Chunk-level retrieval</li>
							<li>Exact traceability from answer to chunk</li>
							<li>uploaded_by made nullable</li>
							<li>Dedicated reset endpoint</li>
							<li>Correct PostgreSQL sequence resets</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 3: Chunking Strategy</h3>
						<ul>
							<li>Fixed-size chunks (~800 characters)</li>
							<li>Sequential slicing</li>
							<li>No overlap</li>
							<li>Chunk boundaries may split ideas</li>
							<li>Accepted intentionally</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 4: Embedding Pipeline</h3>
						<ul>
							<li>Chunk text sent to embedding model</li>
							<li>Vectors stored alongside chunks</li>
							<li>Fully async pipeline</li>
							<li>Strict length checks</li>
							<li>Hard failure on mismatches</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 5: Retrieval Logic</h3>
						<ul>
							<li>User question embedded</li>
							<li>Similarity computed against chunk embeddings</li>
							<li>Explicit filtering by document IDs</li>
							<li>Top-k chunks returned</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 6: Generation Layer</h3>
						<ul>
							<li>LLM instructed to use only provided context</li>
							<li>Explicit “I don’t know” behavior</li>
							<li>Hallucination prevention</li>
							<li>Grounded, traceable answers</li>
						</ul>
					</div>

					<div class="subsection">
						<h3>Phase 7: Frontend & State Management</h3>
						<ul>
							<li>Upload up to 3 TXT files</li>
							<li>Persistent document ID tracking</li>
							<li>Continuous logs</li>
							<li>Explicit reset button</li>
							<li>Frontend state bugs surfaced clearly</li>
						</ul>
					</div>
				</div>

				<!-- LIMITATIONS -->
				<div class="section">
					<h2>Known Limitations</h2>
					<ul>
						<li>TXT files only</li>
						<li>No conversation memory</li>
						<li>Simple chunking</li>
						<li>No authentication</li>
						<li>Very barebones UI</li>
					</ul>
				</div>
			</main>
		</div>
	</body>
</html>
